{
"Taxonomy":"Our taxonomy aims to not only propose a first systematic approach to the more intrinsic (technological) characteristics of Collaborative AR, but also to put them in relation to key characteristics of collaborative work.<br><br>In what follows the different dimensions included in the taxonomy are presented (Team; Time; Task; Communication; Scene Capture and Tracking; Shared Context Sources; Level of User Actuation; Output and Augmentation; Input Modalities; Research) and the considered categories and characteristics detailed and discussed. Additionally, for easier reference, for each dimension, a companion table is provided with a summary of the proposed categories and characteristics.",
"Team":"The characteristics of a team involved in a collaborative effort define much of how the tasks progress. First of all, the <div class=\"dimensionsup\">physical distribution</div> of its members, if they are in the same location (<div class=\"dimension\">collocated</div>, if they are all in remote locations (<div class=\"dimension\">distributed</div>) or a mix of these two cases (<div class=\"dimension\">mixed-presence</div>). This corresponds to one of the dimensions identified in the seminal work of Johansen.<br><br>Another important aspect dictating how the teams need to work is their <div class=\"dimensionsup\">role structure</div>. If the team is <div class=\"dimension\">functional</div>, it means that each member has a specific function or expertise, but if the team is <div class=\"dimension\">divisional</div>, all elements have the same level of expertise, but collaborate to divide the work.<br><br><div class=\"dimensionsup\">Coupling</div> between team members is related to the dependency to one another, and ca be divided in <div class=\"dimension\">tightly coupled</div>, i.e.,  collaborators can only progress by interacting with each other and <div class=\"dimension\">loosely coupled</div>, i.e., when participants can work independently for a long time.<br><br>The team's <div class=\"dimensionsup\">size</div> is also an important aspect to consider, since it can have impact on several aspects during design and run-time, for instance, in how to make it clear, for all, who is intervening or performing a certain task, at a certain time. At this stage, we distinguish between <div class=\"dimension\">two</div> or <div class=\"dimension\">multiple</div> (i.e., 3+) elements. <br><br>Team <div class=\"dimensionsup\">life-span</div> (or permanence), refers to the amount of time a team exists as so. If a team is assembled to tackle a particular task and, then disbanded, it is said to be <div class=\"dimension\">short-term</div>; however, if the team persists, over time, it is classified as <div class=\"dimension\">long-term</div>.<br><br>Team <div class=\"dimensionsup\">turnover</div> refers to the amount of expected change in the elements intervening in the collaborative effort, i.e., how often team members leave and/or new team members are added, ranging between <div class=\"dimension\">low</div>, <div class=\"dimension\">intermediate</div> or <div class=\"dimension\">high</div>.<br><br>Moreover, <div class=\"dimensionsup\">technology usage</div> includes the amount of effort devoted to the use of technology, i.e., how frequently technological solutions are used during the collaboration effort. In this context, team members may use it <div class=\"dimension\">sometimes, continuous</div> .<br><br>Finally, a <div class=\"dimensionsup\">multidisciplinary</div> team, i.e., the presence of members with different backgrounds and perspectives over the task (analogous to the number of communities of practice discussed by Lee and Paine), might pose particular challenges regarding how, e.g., a more elaborate context needs to be provided, communication is supported, or adaptation needs to be available to allow custom discipline specific augmentation.",
"Time": "This dimension groups those characteristics that relate to the time aspects of the collaboration and three main characteristics are considered: <div class=\"dimensionsup\">synchronicity</div>, i.e., if all team members are present and can act in real time (<div class=\"dimension\">synchronous</div>), or if collaborative actions, performed by different elements, take place at different times (<div class=\"dimension\">asynchronous</div>). The <div class=\"dimension\">mixed</div> synchronicity refers to the fact that supporting both might be relevant, for some tasks; <div class=\"dimensionsup\">duration</div>, refers to the time required for the collaboration effort, without interruption, to accomplish, e.g., a <div class=\"dimension\">short</div> (less than 30min), <div class=\"dimension\">intermediate</div> (between 30min and 90min), or <div class=\"dimension\">long</div> (more than 90min) task. This is important, since a certain setup might be adequate for short usage times, but be uncomfortable for longer periods; and <div class=\"dimensionsup\">predictability</div> of the collaboration describes if it happens at well-defined <div class=\"dimension\">schedules</div> (predictable) or <div class=\"dimension\">unscheduled</div> (unpredictable) times.",
"Task": "The task is central in a collaborative effort and dictates much of the communication, information, and augmentation requirements. Regarding the task <div class=\"dimensionsup\">type</div>, it can be divided in: 1) <div class=\"dimension\">management</div>, where someone assumes the supervision and coordination of others; 2) <div class=\"dimension\">advisory</div>, entailing professional support, e.g., providing expert advice; 3) <div class=\"dimension\">negotiation</div>, when two or more parties need to resolve conflicts and reach agreement; 4) <div class=\"dimension\">psycho-motor</div> action, referring to those tasks consisting of the manipulation of a machine or product involving elaborate movements and/or psychological processing. 5) <div class=\"dimension\">defined problem</div>, i.e., problems with well defined answers, e.g., when a remote expert has the solution and provides instructions; 6) <div class=\"dimension\">ill-defined problem</div>, when no partner has an immediate solution and they, e.g., generate/share ideas or plans through brainstorming. <br><br><div class=\"dimensionsup\">Interdependence</div> describes how team member actions are influenced or limited by those from other members and can be: 1) <div class=\"dimension\">pooled</div>, when each member can make their contribution independently from others; 2) <div class=\"dimension\">sequential</div>, when the actions performed by one team member need to follow an action performed by any another member; 3) <div class=\"dimension\">reciprocal</div>, when two team members act alternately; and 4) <div class=\"dimension\">intensive</div>, when all team members need to work simultaneously to accomplish the task <br><br>Finally, it is relevant to know if the task is performed in an <div class=\"dimensionsup\">environment</div> located <div class=\"dimension\">indoor, outdoor, or mixed</div> between the two, since this might impact on how the system is designed.",
"Communication": "The communication <div class=\"dimensionsup\">structure</div> describes how the message flows inside the team. Inheriting from the work of Wildman et al., three structures can be considered: 1) <div class=\"dimension\">hub-and-wheel</div>, where all communication passes through one team element (e.g., a leader), and flows to others through him/her; 2) <div class=\"dimension\">chain</div>, where the message reaches each team element through a hierarchy; and 3) <div class=\"dimension\">star</div>, where every team member freely passes and receives information from others.<br><br>The communication <div class=\"dimensionsup\">mode</div> characterizes what communicative elements are possible, such as <div class=\"dimension\">verbal, textual</div> (e.g., messaging), <div class=\"dimension\">graphical</div> (e.g., sketch), or <div class=\"dimension\">gestural</div> (e.g., hand gestures) elements.<br><br>Communication is also characterized by the <div class=\"dimensionsup\">intent</div> that it serves: <div class=\"dimension\">inform, commit, guide, request, express, decide, propose, respond, and record</div>. The identification of intent is an important characteristic of communication. It emphasizes the existence of an explicit goal, marking a notable difference to other aspects of the collaboration dynamics which, although related to communication, are not explicit. For instance, using hand gestures to, explicitly, convey or complement a message (e.g., pointing to a specific area) is communication related, while sharing hands' position to contextualize how the task is being performed would not.<br><br><div class=\"dimensionsup\">Frequency</div> characterizes how often communication can (or needs to) occur to accomplish the task: <div class=\"dimension\">never, sometimes, and continuous</div>, and <div class=\"dimensionsup\">duration</div>: e.g., <div class=\"dimension\">short</div> (less than 5 seconds), <div class=\"dimension\">intermediate</div> (between 5s and 5min) or <div class=\"dimension\">long</div> (more than 5min). Both these aspects are dependant (or might face challenges) on a number of other factors such as the type of task and team distribution. For instance, for particular tasks, frequent communication might be mandatory.",
"Scene Capture and Tracking": "A first aspect to consider is <div class=\"dimensionsup\">point-of-interest tracking</div>, i.e., how the system knows where are the relevant key features (e.g., objects, location) enabling proper registration of the augmented content. In this regard, we identify three options: 1) <div class=\"dimension\">computer vision</div> methods, resorting to marker or markerless approaches; 2) <div class=\"dimension\">sensor</div> (e.g., electromagnetic, GPS); or 3) <div class=\"dimension\">non-existent</div>. The latter option encompasses those situations for which augmentation is done without a direct connection with scene elements, e.g., instructions provided by remote teammates presented on the corner of an on-site technician field-of-view, while he performs a maintenance procedure.<br><br>The <div class=\"dimensionsup\">apparatus</div> is the technological device used to support scene capture (and tracking) and can range from a simple <div class=\"dimension\">camera</div>, to more complex devices, such as <div class=\"dimension\">stereo cameras</div> or <div class=\"dimension\">depth cameras</div>.<br><br>Finally, <div class=\"dimensionsup\">viewpoint</div> refers to the nature of the views of the scene that are available. In this regard, we consider three alternatives: 1) <div class=\"dimension\">fixed</div>, e.g., from a fixed overhead camera; 2) <div class=\"dimension\">mobile, dependant</div> on the user, e.g., from a handheld device or a user mounted camera providing POV; and 3) <div class=\"dimension\">mobile, independent</div>, e.g., a camera mounted in a robotic arm that can be oriented to provide any particular view.",
"Shared Context Sources": "Context-awareness is a field of research deserving strong attention in multiple areas. In this regard, it is important to distinguish two main purposes: 1) to provide the computational system with a context that might enable adaptive behaviors; and 2) provide the users with information that contextualizes the task they are involved in Antunes e DelAmo.Regarding collaboration and AR, two notable examples of a systematic (taxonomic) approach to the subject are the works by Grubert et al., performed in the context of their proposal of the concept of Pervasive AR, and by Collazos et al., proposing a taxonomy for context information sources in the scope of their descriptive theory of awareness for groupware development. Here, we leave out the subject of discussing which context sources can be considered for providing adaptive system features (see for an in-depth discussion on system context-awareness). Instead, we focus on these context elements considering their potential importance to increase the awareness of team members regarding the collaborative context. Since system-side context-awareness has a parallel with collaborative context awareness (by sharing a range of context sources), we consider the nomenclature proposed by Grubert et al. selecting those dimensions and characteristics with a more immediate relevance for collaborative scenarios and inherit, where deemed relevant. To clarify, we do not consider as context those elements that arise from explicit communication by any team member. Furthermore, it is important to note that context sharing is not only useful for remote collaboration, but can also be an important resource in collocated efforts. In fact, the increasingly common multi-device ecologies often generate team and task awareness fragmentation that might be tackled by an explicit presentation of context elements.<br><br><div class=\"dimensionsup\">Human</div> factors, i.e., those pertaining team members and their performance, encompass <div class=\"dimension\">personal</div>, <div class=\"dimension\">task-specific</div>, and <div class=\"dimension\">social</div> aspects.Personal human factors specifically relate to individual user characteristics or states including, e.g., age, abilities and knowledge, perceptual, cognitive (e.g., cognitive load) and affective states.Additionally, it can also encompass aspects directly specifying the user's context within the task, such as gaze orientation and focus (point-of-interest), availability, location, task progression, and motor activity. Social human factors account for the broader scope of interaction among people. The dimension of social interaction in collaborative efforts is highly relevant as it fosters improved learning, group formation and group dynamics. Considering the framework proposed by Kreijns et al., social interaction depends on the systems sociability, on social presence, and on the creation of a social space. The extent to which these elements are present depends on several aspects, such as the supported level of communication, but also greatly depends on how social cues are made available to team members.<br><br><div class=\"dimensionsup\">Environmental</div> factors concern everything about the <div class=\"dimension\">physical</div> and <div class=\"dimension\">digital</div> (i.e., augmented) environment that the user is experiencing. The physical environmental factors describe the characteristics of the place where the user is positioned including elements such as temperature, ambient noise and light intensity, and the spatial and geometric configuration of relevant artefacts. Digital environmental factors refer to elements that provide context about the characteristics of the AR environment and the features it provides. This is important in certain contexts, in which team members rely on different technological resources which should be known by other members is critical to guarantee success of collaboration teams. For example, the amount of information each team member views, if the tracking/alignment mechanism are working properly, if all virtual elements are being rendered in a satisfactory manner, the availability of adequate infrastructure factors, like bandwidth for distance technology tools, state-of-the-art workstations or the availability of technical support. Additionally, it might also be relevant to have an awareness of what lies beyond the boundaries, i.e., <div class=\"dimension\">peripheral</div> of the collaboration space. Peripheral environmental factors concern information which is not directly related with the collaborative setting and task, but with awareness (both physical and semantic) of the surrounding conditions for that space. For instance, if the user keeps a notion of other people or events around, not involved in the collaboration, while performing the task. Or if non-related notifications and information reach the user, e.g., email notifications.<br><br><div class=\"dimensionsup\">Collaborative</div> factors pertain information that provides a wide contextualization of the collaboration effort, further supporting, for instance, the conditions required for coordination, complementing communication, an aspect considered of the utmost relevance for collaborative work, by contributing to  a shared team cognition and  potentially driving anticipatory behavior and implicit coordination. The collaborative <div class=\"dimension\">timeline</div> refers to information regarding the sequence of past relevant actions of different team members, and annotations or outcomes that would, for example, provide a reference procedure to solve a problem, a context of what has been attempted or performed, so far, or support auditing procedures. In turn, the <div class=\"dimension\">progression</div> of the collaborative effort refers to a less granular level of information than the timeline. While the latter can work similarly to a logbook, progression entails an additional level of detail providing team members with a runtime performance monitoring of each member of the team on their current task (including self monitoring). This can be important to enable a team-level perspective of the ongoing work, serve to support team coordination, and help create some of the conditions required for the team to adjust to different phases of the tasks , e.g. informing when expert support may be required and, facilitating the articulation of individual actions with the collaborative efforts. <div class=\"dimension\">Presence</div> goes beyond the simple information regarding the location or availability of a team member (as included in the personal factors, above), as it entails a sense of someone being present and following what the person is doing. The inclusion of such feature (e.g., through avatars) is relevant since it potentially enables a remote collaboration experience and performance that is closer to what is possible in collocated work. Additionally, research hints that, as happens with collocated work, the sense of someone being present might have an influence on team member performance. For instance, Miller et al. have shown how a sense of presence might have a social facilitation or inhibition effect depending on the difficulty of the task being performed: having the sense of someone present, when performing a difficult task, lowered performance.",
"Level of User Actuation": "The user's actuation ability can range from <div class=\"dimension\">passive-view</div>, which can be <div class=\"dimension\">on-site or remote</div>, to <div class=\"dimension\">interacting / exploring</div>, e.g., manipulating content present in the scene, and to <div class=\"dimension\">sharing / creating</div>, e.g., adding annotations to the scene or new views or content that others can see. According to Isenberg et al., these are associated to the level of engagement in collaborative visualization and may vary between none, on-site or remote. We chose 'actuation' to avoid a clash with 'engagement' also being used, in the literature, to refer to, e.g., the amount of motivation and commitment a user is devoting to a task.<br><br>A user involved in AR-supported collaborative is also influenced by the level of <div class=\"dimension\">symmetry</div>, which represents if all parts have the same level of actuation, i.e., <div class=\"dimension\">symmetric</div> - whether collaborators have the same basic roles and capabilities, <div class=\"dimension\">asymmetric</div> - whether they have different roles or differences in ability or <div class=\"dimension\">fully asymmetric</div> - a remote user should be equipped with the functionalities and interaction methods that can help solve a local userâ€™s problem without any help of a local user.",
"Output and Augmentation": "We choose to have a level devoted to the sensory <div class=\"dimensionsup\">channel</div> receiving the output rather than directly addressing the technological apparatus since this enables an easier grasp of which channels are specifically considered, to avoid uncertainty when the device might serve many channels (e.g., a tablet might provide visual, haptic, and auditory output). Additionally, centering the categories on the users, it should enable a more versatile categorization to encompass novel technologies and devices. In this line of thought, our proposal inherits from the detailed work of Augstein and Neumayr proposing a human-centered taxonomy for interaction. The authors identify six modalities (sensory channels), related to human perception capabilities from which our work inherits to characterize output augmentation. Output and Augmentation can be performed through: <div class=\"dimension\">vision</div>, including standalone self appearance changing devices (e.g., monitor), their wearable alternatives (e.g., HMD), and external medium appearance changing devices, i.e., devices that can change the appearance of an external element (e.g., video projector); <div class=\"dimension\">audition</div>, considering airborne sound propagation (e.g., sound speakers), through a structure (e.g., bone), and possibly wearable (e.g., headphones); <div class=\"dimension\">touch</div>, including tactility (i.e., devices that simulate being touched), haptics (i.e., devices that shift their physical properties, e.g., shape, temperature) and vibration, also considering wearable alternatives; <div class=\"dimension\">kinesthetics</div>, considering our senses of proprioception (i.e., body orientation and position), equilibrioception (i.e., body balance), and kinematics (i.e., acceleration); <div class=\"dimension\">olfaction</div> through a device located in the ambient or wearable (e.g., olfactometer); and <div class=\"dimension\">gustation</div>. Additionally, Augstein and Neumayr distinguish between the set of channels above, which entail a perception/action from one of the senses that is further processed by (or originates at) the brain, i.e., indirect processing, and those that directly deal with brain or muscle activity, i.e., direct processing. For the latter, the authors identify: <div class=\"dimension\">neural oscillation</div> and <div class=\"dimension\">galvanism</div>.<br><br>To explicitly convey if a system allows multimodal augmentation, i.e., through multiple channels, <div class=\"dimensionsup\">mode</div> can be: <div class=\"dimension\">unimodal</div>, if only a channel is used, at each time, regardless of how many are available; <div class=\"dimension\">redundant</div>,  and/or <div class=\"dimension\">complementary</div>, if multiple augmentation channels are used to reinforce or add information, respectively. Finally, <div class=\"dimensionsup\">customization</div> refers to the possibility of the user (<div class=\"dimension\">adaptable</div>) and/or the system (<div class=\"dimension\">adaptive</div>) to automatically choose and/or customize the most suited channels for output and augmentation.",
"Input Modalities": "For the input modalities, we adopt a similar rationale as the one adopted for the output modalities, considering a human-centered characterization aligned with the work of Augstein and Neumayr, encompassing the following six <div class=\"dimensionsup\">channels</div> related to human perception: <div class=\"dimension\">vision</div>, covering fixed (e.g., kinect) or wearable (e.g., eyetraker glasses) devices that capture/process visual data; <div class=\"dimension\">audition</div>, including devices that capture airborne sound waves (e.g., microphone), through structural propagation in other materials (e.g., ear-bone microphone), and if they are wearable; <div class=\"dimension\">touch</div>, encompassing tactility (i.e., a device sits passively and is touched), haptics (manipulation of an explorable physical surface, e.g., braille keyboard) and vibration (a device sensing vibrations, e.g., tremors); <div class=\"dimension\">kinesthetics</div>, considering proprioception (i.e., position and orientation of the body), equilibrioception (i.e., body balance), and kinematics (i.e., acceleration); <div class=\"dimension\">olfaction</div>; and <div class=\"dimension\">gustation</div>. Additionally, two channels are considered to cover input though brain or dermal activity, i.e., <div class=\"dimension\">neural oscillation</div> and <div class=\"dimension\">galvanism</div>.<br><br><div class=\"dimensionsup\">Mode</div> refers to how the available modalities can be used to perform interaction. As for the <div class=\"dimension\">output and augmentation</div> dimension, we consider the options <div class=\"dimension\">unimodal</div>, when only one modality can be used, at once, and when these are explored together: <div class=\"dimension\">redundant</div>, when modalities can be used simultaneously to perform the same action, or <div class=\"dimension\">complementary</div>, when multiple modalities are used in sequence to provide different parts of an action (e.g., pointing to an annotation and saying \"delete\").<br><br>Finally, <div class=\"dimensionsup\">customization</div> refers to the possibility of the user (<div class=\"dimension\">adaptable</div>) and/or the system to automatically choose (<div class=\"dimension\">adaptive</div>) the most suited channel.",
"Research": "The last dimension we have considered is devoted to research, allowing to clarify the maturity and detail of the collaborative work being reported. Research can be defined as the investigation and study of materials aimed at the interpretation of data, in order to establish facts and reach new conclusions.<br><br>In this context, the research <div class=\"dimensionsup\">domain</div>, or topic is associated to the area of application, ranging between <div class=\"dimension\">medicine, industrial, education/training, architecture/construction, tourism/heritage, entertaining/gaming</div>, among others.<br><br>According to the collaborative effort and the tasks being addressed, the research <div class=\"dimensionsup\">context</div> may vary between <div class=\"dimension\">basic research</div>, i.e., the technologies and/or methods investigated are novel and have not matured, yet, to be usable in real scenarios, often considering dummy tasks as the case study (e.g., assembly of Lego blocks, tangram puzzles) and evaluation; and <div class=\"dimension\">applied research</div>, i.e., the technologies and methods are implemented in practice using problems inspired by real-world scenarios (e.g., industry related procedures), and an evaluation of the technique is conducted for those scenarios.<br><br>There are various types of scientific studies. The choice of <div class=\"dimensionsup\">study type</div> mainly depends on the research goal, and may vary between <div class=\"dimension\">pilot</div>, i.e., small-scale preliminary studies aimed to investigate crucial components of a main study; <div class=\"dimension\">informal</div>, i.e., studies aimed at getting more input, in a quicker manner, without following any structured method; <div class=\"dimension\">formal</div>, i.e., studies that follow structured methods to obtain measures; <div class=\"dimension\">field</div>, i.e., studies conducted outside a laboratory environment."
}